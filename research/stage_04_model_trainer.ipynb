{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b37720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526b8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_checkpoint: Path\n",
    "\n",
    "    num_train_epochs: int\n",
    "    learning_rate: float\n",
    "    warmup_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    gradient_accumulation_steps: int\n",
    "    weight_decay: float\n",
    "\n",
    "\n",
    "    optim: str\n",
    "    lr_scheduler_type: str\n",
    "\n",
    "\n",
    "    use_cpu: bool\n",
    "    use_fp16: bool\n",
    "    tf32: bool\n",
    "    gradient_checkpointing: bool\n",
    "    dataloader_pin_memory: bool\n",
    "    dataloader_num_workers: int\n",
    "    torch_empty_cache_steps: int\n",
    "\n",
    "\n",
    "    logging_strategy: str\n",
    "    logging_steps: int\n",
    "    eval_strategy: str\n",
    "    eval_steps: int\n",
    "    save_strategy: str\n",
    "    save_steps: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.summarizer.utils.common import create_directories\n",
    "from src.summarizer.utils.common import read_yaml,create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "            config = read_yaml(self.config.model_trainer)\n",
    "            params = read_yaml(self.params.model_trainer)\n",
    "\n",
    "            create_directories([config.root_dir])\n",
    "\n",
    "            model_trainer_config = ModelTrainerConfig(root_dir=config.root_dir,\n",
    "                                                    data_path=config.data_path,\n",
    "                                                    model_checkpoint=config.model_checkpoint,\n",
    "                                                    num_train_epochs=params.num_train_epochs,\n",
    "                                                    learning_rate=params.learning_rate,\n",
    "                                                    warmup_steps=params.warmup_steps,\n",
    "                                                    per_device_train_batch_size=params.per_device_train_batch_size,\n",
    "                                                    per_device_eval_batch_size=params.per_device_eval_batch_size,\n",
    "                                                    gradient_accumulation_steps=params.gradient_accumulation_steps,\n",
    "                                                    weight_decay=params.weight_decay,\n",
    "                                                    optim=params.optim,\n",
    "                                                    lr_scheduler_type=params.lr_scheduler_type,\n",
    "                                                    use_cpu=params.use_cpu,\n",
    "                                                    use_bf16=params.bf16,\n",
    "                                                    seed=params.seed,\n",
    "                                                    data_seed=params.data_seed,\n",
    "                                                    tf32=params.tf32,\n",
    "                                                    gradient_checkpointing=params.gradient_checkpointing,\n",
    "                                                    dataloader_pin_memory=params.dataloader_pin_memory,\n",
    "                                                    dataloader_num_workers=params.dataloader_num_workers,\n",
    "                                                    torch_empty_cache_steps=params.torch_empty_cache_steps,\n",
    "                                                    logging_strategy=params.logging_strategy,\n",
    "                                                    logging_steps=params.logging_steps,\n",
    "                                                    eval_strategy=params.eval_strategy,\n",
    "                                                    eval_steps=params.eval_steps,\n",
    "                                                    save_strategy=params.save_strategy,\n",
    "                                                    save_steps=params.save_steps,\n",
    "                                                    report_to=params.report_to,\n",
    "                                                    load_best_model_at_end=params.load_best_model_at_end,\n",
    "                                                    generation_num_beams=params.generation_num_beams,\n",
    "                                                    generation_max_length=params.generation_max_length,\n",
    "                                                    predict_with_generate=params.predict_with_generate,\n",
    "                                                    train_fraction=params.train_fraction,\n",
    "                                                    eval_fraction=params.eval_fraction,\n",
    "                                                    max_grad_norm=params.max_grad_norm,\n",
    "                                                    torch_compile=params.torch_compile)\n",
    "            \n",
    "            return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.summarizer.entity.config_entity import ModelTrainerConfig\n",
    "import torch\n",
    "import evaluate \n",
    "import numpy as np \n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True \n",
    "torch.backends.cudnn.allow_tf32 = True \n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self,config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def compute_metrics(self, eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "\n",
    "        # Handle tuple output\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        # Convert to numpy safely\n",
    "        preds = np.array(preds)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Replace invalid values\n",
    "        preds[preds < 0] = self.tokenizer.pad_token_id\n",
    "        preds[preds >= self.tokenizer.vocab_size] = self.tokenizer.pad_token_id\n",
    "\n",
    "        labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
    "\n",
    "        # Force safe dtype\n",
    "        preds = preds.astype(np.int64)\n",
    "        labels = labels.astype(np.int64)\n",
    "\n",
    "        decoded_preds = self.tokenizer.batch_decode(\n",
    "            preds.tolist(),   #critical: convert to Python lists\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "        decoded_labels = self.tokenizer.batch_decode(\n",
    "            labels.tolist(),\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "        decoded_preds = [\"\\n\".join(p.split(\". \")) for p in decoded_preds]\n",
    "        decoded_labels = [\"\\n\".join(l.split(\". \")) for l in decoded_labels]\n",
    "\n",
    "        rouge = evaluate.load(\"rouge\")  # Load rouge here\n",
    "        \n",
    "        result = rouge.compute(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "            use_stemmer=True,\n",
    "        )\n",
    "\n",
    "        result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "\n",
    "        gen_lens = [np.count_nonzero(p != self.tokenizer.pad_token_id) for p in preds]\n",
    "        result[\"gen_len\"] = float(np.mean(gen_lens))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_checkpoint)\n",
    "        self.tokenizer = tokenizer\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_checkpoint)\n",
    "\n",
    "        data_collator = DataCollatorForSeq2Seq(tokenizer=self.tokenizer,\n",
    "                                               model=model)\n",
    "\n",
    "        dataset_dict = load_from_disk(self.config.data_path)\n",
    "\n",
    "        train_frac = self.config.train_fraction\n",
    "        eval_frac = self.config.eval_fraction\n",
    "\n",
    "        train_dataset = (\n",
    "            dataset_dict[\"train\"]\n",
    "            .shuffle(seed=42)\n",
    "            .select(range(int(len(dataset_dict[\"train\"]) * train_frac)))\n",
    "        )\n",
    "\n",
    "        eval_dataset = (\n",
    "            dataset_dict[\"validation\"]\n",
    "            .shuffle(seed=42)\n",
    "            .select(range(int(len(dataset_dict[\"validation\"]) * eval_frac)))\n",
    "        )\n",
    "\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=self.config.root_dir,\n",
    "\n",
    "            # Core training\n",
    "            num_train_epochs=self.config.num_train_epochs,\n",
    "            learning_rate=self.config.learning_rate,\n",
    "            warmup_steps=self.config.warmup_steps,\n",
    "            per_device_train_batch_size=self.config.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=self.config.per_device_train_batch_size,\n",
    "            gradient_accumulation_steps=self.config.gradient_accumulation_steps,\n",
    "            weight_decay=self.config.weight_decay,\n",
    "\n",
    "            # Optimizer & scheduler\n",
    "            optim=self.config.optim,\n",
    "            lr_scheduler_type=self.config.lr_scheduler_type,\n",
    "\n",
    "            # Precision & performance\n",
    "            bf16=self.config.use_bf16,\n",
    "            tf32=self.config.tf32,\n",
    "            dataloader_pin_memory=self.config.dataloader_pin_memory,\n",
    "            dataloader_num_workers=self.config.dataloader_num_workers,\n",
    "\n",
    "            # Logging / eval / saving\n",
    "            logging_strategy=self.config.logging_strategy,\n",
    "            logging_steps=self.config.logging_steps,\n",
    "            eval_strategy=self.config.eval_strategy,\n",
    "            eval_steps=self.config.eval_steps,\n",
    "            save_strategy=self.config.save_strategy,\n",
    "            save_steps=self.config.save_steps,\n",
    "\n",
    "            # Misc\n",
    "            report_to=self.config.report_to,  # avoids wandb unless you want it\n",
    "            load_best_model_at_end=self.config.load_best_model_at_end,\n",
    "            generation_num_beams=self.config.generation_num_beams,\n",
    "            generation_max_length=self.config.generation_max_length,\n",
    "            predict_with_generate=self.config.predict_with_generate,\n",
    "            max_grad_norm=self.config.max_grad_norm,\n",
    "            torch_compile=self.config.torch_compile\n",
    "        )\n",
    "\n",
    "        trainer = Seq2SeqTrainer(model=model,\n",
    "                          args=training_args,\n",
    "                          processing_class=self.tokenizer,\n",
    "                          data_collator=data_collator,\n",
    "                          train_dataset=train_dataset,\n",
    "                          eval_dataset=eval_dataset,\n",
    "                          compute_metrics=self.compute_metrics)\n",
    "        \n",
    "        trainer.train()\n",
    "\n",
    "        model.save_pretrained(os.path.join(self.config.root_dir, \"model\"))\n",
    "        self.tokenizer.save_pretrained(os.path.join(self.config.root_dir, \"tokenizer\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_summ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
